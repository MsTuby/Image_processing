# This python script tracks and blurs the object in a video stream or webcam feed
# Install the required packages if not already installed:
# pip install imutils opencv-python numpy
# pip install opencv-contrib-python
# pip install numpy opencv-python

from imutils.video import VideoStream
from imutils.video import FPS
import argparse
import imutils
import time
import cv2
import numpy


def argsParser():
	
	# construct the argument parser and parse the arguments
	ap = argparse.ArgumentParser()
	ap.add_argument("-v", "--video", type=str,
		help="path to input video file")
	ap.add_argument("-t", "--tracker", type=str, default="kcf",
		help="OpenCV object tracker type")
	args = vars(ap.parse_args())

	return args


def init_tracker(tracker):
    # For OpenCV 4.5+ (and 5.x), use cv2.legacy if available
    if hasattr(cv2, 'legacy'):
        OPENCV_OBJECT_TRACKERS = {
            "csrt": cv2.legacy.TrackerCSRT_create,
            "kcf": cv2.legacy.TrackerKCF_create,
            "boosting": cv2.legacy.TrackerBoosting_create,
            "mil": cv2.legacy.TrackerMIL_create,
            "tld": cv2.legacy.TrackerTLD_create,
            "medianflow": cv2.legacy.TrackerMedianFlow_create,
            "mosse": cv2.legacy.TrackerMOSSE_create
        }
    else:
        OPENCV_OBJECT_TRACKERS = {
            "csrt": cv2.TrackerCSRT_create,
            "kcf": cv2.TrackerKCF_create,
            "boosting": cv2.TrackerBoosting_create,
            "mil": cv2.TrackerMIL_create,
            "tld": cv2.TrackerTLD_create,
            "medianflow": cv2.TrackerMedianFlow_create,
            "mosse": cv2.TrackerMOSSE_create
        }
    tracker = OPENCV_OBJECT_TRACKERS[tracker]()

    return tracker


def run_object_tracker(args):

	# initialize the bounding box coordinates of the object we are going
	# to track
	initBB = None

	# initialize a tracker object
	tracker = init_tracker(args["tracker"])

	# if a video path was not supplied, grab the reference to the web cam
	if not args.get("video", False):
		print("[INFO] starting video stream...")
		vs = cv2.VideoCapture(0)
	# otherwise, grab a reference to the video file
	else:
		vs = cv2.VideoCapture(args["video"])
 
	# initialize the FPS throughput estimator
	fps = None

	# loop over frames from the video stream
	while vs.isOpened():
		# grab the current frame using a VideoCapture object
		(ret, frame) = vs.read()
	
		# check to see if we have reached the end of the stream
		if not ret:
			break
	
		# resize the frame (so we can process it faster) and grab the
		# frame dimensions
		frame = imutils.resize(frame, width=500)
		(H, W) = frame.shape[:2]

		# check to see if we are currently tracking an object
		if initBB is not None:
			# grab the new bounding box coordinates of the object
			(success, box) = tracker.update(frame)
	
			# check to see if the tracking was a success
			if success:
				(x, y, w, h) = [int(v) for v in box]
				cv2.rectangle(frame, (x, y), (x + w, y + h),
					(0, 255, 0), 2)
	
			# update the FPS counter
			fps.update()
			fps.stop()
	
			# initialize the set of information we'll be displaying on
			# the frame
			info = [
				("Tracker", args["tracker"]),
				("Success", "Yes" if success else "No"),
				("FPS", "{:.2f}".format(fps.fps())),
			]
	
			# loop over the info tuples and draw them on our frame
			for (i, (k, v)) in enumerate(info):
				text = "{}: {}".format(k, v)
				cv2.putText(frame, text, (10, H - ((i * 20) + 20)),
					cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

		# show the output frame
		cv2.imshow("Frame", frame)
		key = cv2.waitKey(1) & 0xFF
	
		# if the 's' key is selected, we are going to "select" a bounding
		# box to track
		if key == ord("s"):
			# select the bounding box of the object we want to track (make
			# sure you press ENTER or SPACE after selecting the ROI)
			initBB = cv2.selectROI("Frame", frame, fromCenter=False,
				showCrosshair=True)
	
			# start OpenCV object tracker using the supplied bounding box
			# coordinates, then start the FPS throughput estimator as well
			tracker.init(frame, initBB)
			fps = FPS().start()

		# if the `q` key was pressed, break from the loop
		elif key == ord("q"):
			break
	
	# release the pointer
	vs.release()
		
	# close all windows
	cv2.destroyAllWindows()


def run_object_sharpening(args):
    initBB = None
    tracker = None
    template = None
    vs = cv2.VideoCapture(0) if not args.get("video", False) else cv2.VideoCapture(args["video"])

    while vs.isOpened():
        ret, frame = vs.read()
        if not ret:
            break

        frame = imutils.resize(frame, width=500)
        (H, W) = frame.shape[:2]

        # If tracking, update the tracker and sharpen the tracked region
        if initBB is not None and tracker is not None:
            (success, box) = tracker.update(frame)
            if success:
                (x, y, w, h) = [int(v) for v in box]
                roi = frame[y:y+h, x:x+w]

                # Sharpening kernel
                kernel = numpy.array([[0, -1, 0],
                                      [-1, 5, -1],
                                      [0, -1, 0]])
                sharpened_roi = cv2.filter2D(roi, -1, kernel)
                frame[y:y+h, x:x+w] = sharpened_roi

                # Draw rectangle around sharpened area
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            else:
                # If tracking fails, try to re-detect using template matching
                if template is not None:
                    res = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)
                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)
                    threshold = 0.7  # You may need to adjust this
                    if max_val > threshold:
                        x, y = max_loc
                        h, w = template.shape[:2]
                        initBB = (x, y, w, h)
                        tracker = init_tracker(args["tracker"])
                        tracker.init(frame, initBB)
                        # Draw rectangle for feedback
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
                    else:
                        cv2.putText(frame, "Object lost! Trying to re-detect...", (10, 30),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                else:
                    cv2.putText(frame, "Object lost! Press 's' to select.", (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    initBB = None
                    tracker = None

        elif initBB is None or tracker is None:
            cv2.putText(frame, "Press 's' to select object to track & sharpen.", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        cv2.imshow("Frame", frame)
        key = cv2.waitKey(1) & 0xFF

        if key == ord("s"):
            # Select ROI and initialize tracker
            initBB = cv2.selectROI("Frame", frame, fromCenter=False, showCrosshair=True)
            x, y, w, h = [int(v) for v in initBB]
            template = frame[y:y+h, x:x+w].copy()  # Save template for re-detection
            tracker = init_tracker(args["tracker"])
            tracker.init(frame, initBB)
        elif key == ord("q"):
            break

    vs.release()
    cv2.destroyAllWindows()


def run_object_blurring(args):
    initBB = None
    tracker = None
    template = None
    vs = cv2.VideoCapture(0) if not args.get("video", False) else cv2.VideoCapture(args["video"])

    while vs.isOpened():
        ret, frame = vs.read()
        if not ret:
            break

        frame = imutils.resize(frame, width=500)
        (H, W) = frame.shape[:2]

        # If tracking, update the tracker and blur the tracked region
        if initBB is not None and tracker is not None:
            (success, box) = tracker.update(frame)
            if success:
                (x, y, w, h) = [int(v) for v in box]
                roi = frame[y:y+h, x:x+w]

                # Apply Gaussian blur to the ROI
                blurred_roi = cv2.GaussianBlur(roi, (61, 61), 0)
                frame[y:y+h, x:x+w] = blurred_roi

                # Draw rectangle around blurred area
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            else:
                # If tracking fails, try to re-detect using template matching
                if template is not None:
                    res = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)
                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)
                    threshold = 0.7  # You may need to adjust this
                    if max_val > threshold:
                        x, y = max_loc
                        h, w = template.shape[:2]
                        initBB = (x, y, w, h)
                        tracker = init_tracker(args["tracker"])
                        tracker.init(frame, initBB)
                        # Draw rectangle for feedback
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
                    else:
                        cv2.putText(frame, "Object lost! Trying to re-detect...", (10, 30),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                else:
                    cv2.putText(frame, "Object lost! Press 's' to select.", (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    initBB = None
                    tracker = None

        elif initBB is None or tracker is None:
            cv2.putText(frame, "Press 's' to select object to track & blur.", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        cv2.imshow("Frame", frame)
        key = cv2.waitKey(1) & 0xFF

        if key == ord("s"):
            # Select ROI and initialize tracker
            initBB = cv2.selectROI("Frame", frame, fromCenter=False, showCrosshair=True)
            x, y, w, h = [int(v) for v in initBB]
            template = frame[y:y+h, x:x+w].copy()  # Save template for re-detection
            tracker = init_tracker(args["tracker"])
            tracker.init(frame, initBB)
        elif key == ord("q"):
            break

    vs.release()
    cv2.destroyAllWindows()

def main():
    args = argsParser()
    run_object_blurring(args)
    # run_object_sharpening(args)

# Run object tracker
if __name__ == '__main__':
    main()